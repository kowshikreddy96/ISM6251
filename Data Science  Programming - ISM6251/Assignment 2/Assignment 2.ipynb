{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77c9ce09",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c1e7f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy and pandas libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "np.random.seed(1)\n",
    "from sklearn.impute import SimpleImputer\n",
    "# set random seed to ensure that results are repeatable\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2bf63d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,accuracy_score,precision_score,recall_score,f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75756e2d",
   "metadata": {},
   "source": [
    "# Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7738ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(\"X_train_salary_data.csv\")\n",
    "X_test = pd.read_csv(\"X_test_salary_data.csv\")\n",
    "y_train = pd.read_csv(\"y_train_salary_data.csv\")\n",
    "y_test = pd.read_csv(\"y_test_salary_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d23b30",
   "metadata": {},
   "source": [
    "# Model the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3dce779",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance = pd.DataFrame({\"model\": [], \"Accuracy\": [], \"Precision\": [], \"Recall\": [], \"F1\": []})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aac5c2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.replace([np.inf, -np.inf, np.nan], 0, inplace=True)\n",
    "y_test.replace([np.inf, -np.inf, np.nan], 0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744fbae3",
   "metadata": {},
   "source": [
    "# Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "144d4068",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90ca421b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "log_reg_model = LogisticRegression()\n",
    "_ = log_reg_model.fit(X_train, np.ravel(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61dd5087",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression Model</td>\n",
       "      <td>0.778626</td>\n",
       "      <td>0.778898</td>\n",
       "      <td>0.778626</td>\n",
       "      <td>0.776151</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       model  Accuracy  Precision    Recall        F1\n",
       "0  Logistic Regression Model  0.778626   0.778898  0.778626  0.776151"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_preds = log_reg_model.predict(X_test)\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"Logistic Regression Model\", \n",
    "                                                    'Accuracy': accuracy_score(y_test, model_preds) , \n",
    "                                                    'Precision': precision_score(y_test, model_preds, average='weighted') , \n",
    "                                                    'Recall': recall_score(y_test, model_preds, average='weighted'), \n",
    "                                                    'F1': f1_score(y_test, model_preds, average='weighted') }, index=[0])])\n",
    "performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101f88b8",
   "metadata": {},
   "source": [
    "# RandomizedSearchCV Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "27f36b4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV 1/5] END .C=10, penalty=elastic, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END .C=10, penalty=elastic, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END .C=10, penalty=elastic, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END .C=10, penalty=elastic, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END .C=10, penalty=elastic, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END ...C=1, penalty=elastic, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ...C=1, penalty=elastic, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ...C=1, penalty=elastic, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ...C=1, penalty=elastic, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ...C=1, penalty=elastic, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/5] END ..C=0.001, penalty=l1, solver=saga;, score=0.327 total time=   0.0s\n",
      "[CV 2/5] END ..C=0.001, penalty=l1, solver=saga;, score=0.265 total time=   0.0s\n",
      "[CV 3/5] END ..C=0.001, penalty=l1, solver=saga;, score=0.333 total time=   0.0s\n",
      "[CV 4/5] END ..C=0.001, penalty=l1, solver=saga;, score=0.271 total time=   0.0s\n",
      "[CV 5/5] END ..C=0.001, penalty=l1, solver=saga;, score=0.396 total time=   0.0s\n",
      "[CV 1/5] END ...C=0.001, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ...C=0.001, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ...C=0.001, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ...C=0.001, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ...C=0.001, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END ....C=0.1, penalty=l1, solver=saga;, score=0.735 total time=   0.0s\n",
      "[CV 2/5] END ....C=0.1, penalty=l1, solver=saga;, score=0.633 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END ....C=0.1, penalty=l1, solver=saga;, score=0.708 total time=   0.0s\n",
      "[CV 4/5] END ....C=0.1, penalty=l1, solver=saga;, score=0.604 total time=   0.0s\n",
      "[CV 5/5] END ....C=0.1, penalty=l1, solver=saga;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END ...C=0.1, penalty=l2, solver=lbfgs;, score=0.796 total time=   0.0s\n",
      "[CV 2/5] END ...C=0.1, penalty=l2, solver=lbfgs;, score=0.571 total time=   0.0s\n",
      "[CV 3/5] END ...C=0.1, penalty=l2, solver=lbfgs;, score=0.812 total time=   0.0s\n",
      "[CV 4/5] END ...C=0.1, penalty=l2, solver=lbfgs;, score=0.708 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END ...C=0.1, penalty=l2, solver=lbfgs;, score=0.812 total time=   0.0s\n",
      "[CV 1/5] END C=10, penalty=lasso, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=10, penalty=lasso, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=10, penalty=lasso, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=10, penalty=lasso, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=10, penalty=lasso, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END .....C=10, penalty=l1, solver=saga;, score=0.735 total time=   0.0s\n",
      "[CV 2/5] END .....C=10, penalty=l1, solver=saga;, score=0.633 total time=   0.0s\n",
      "[CV 3/5] END .....C=10, penalty=l1, solver=saga;, score=0.708 total time=   0.0s\n",
      "[CV 4/5] END .....C=10, penalty=l1, solver=saga;, score=0.604 total time=   0.0s\n",
      "[CV 5/5] END .....C=10, penalty=l1, solver=saga;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END .C=0.001, penalty=lasso, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/5] END .C=0.001, penalty=lasso, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/5] END .C=0.001, penalty=lasso, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 4/5] END .C=0.001, penalty=lasso, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 5/5] END .C=0.001, penalty=lasso, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/5] END ....C=10, penalty=l2, solver=lbfgs;, score=0.837 total time=   0.0s\n",
      "[CV 2/5] END ....C=10, penalty=l2, solver=lbfgs;, score=0.612 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END ....C=10, penalty=l2, solver=lbfgs;, score=0.792 total time=   0.0s\n",
      "[CV 4/5] END ....C=10, penalty=l2, solver=lbfgs;, score=0.750 total time=   0.0s\n",
      "[CV 5/5] END ....C=10, penalty=l2, solver=lbfgs;, score=0.812 total time=   0.0s\n",
      "The best recall score is 0.7606292517006803\n",
      "... with parameters: {'solver': 'lbfgs', 'penalty': 'l2', 'C': 10}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "25 fits failed out of a total of 50.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1160, in fit\n",
      "    self._validate_params()\n",
      "  File \"C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'elasticnet', 'none' (deprecated), 'l1', 'l2'} or None. Got 'elastic' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1160, in fit\n",
      "    self._validate_params()\n",
      "  File \"C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'elasticnet', 'none' (deprecated), 'l1', 'l2'} or None. Got 'lasso' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.31836735        nan 0.68596939 0.74013605\n",
      "        nan 0.68596939        nan 0.76062925]\n",
      "  warnings.warn(\n",
      "C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"recall\"\n",
    "LR=LogisticRegression()\n",
    "kfolds = 5\n",
    "param_grid = {'C': [0.1, 1, 10,0.001], \n",
    "              \"solver\" : [ 'lbfgs', 'liblinear','saga'],\n",
    "              \"penalty\" : ['l1','l2','lasso','elastic']} \n",
    "  \n",
    "grid = RandomizedSearchCV(LR, param_grid, refit = True, verbose = 3)\n",
    "  \n",
    "# fitting the model for grid search\n",
    "grid.fit(X_train, y_train)\n",
    "print(f\"The best {score_measure} score is {grid.best_score_}\")\n",
    "print(f\"... with parameters: {grid.best_params_}\")\n",
    "\n",
    "bestRecallTree = grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "253663e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression Model</td>\n",
       "      <td>0.778626</td>\n",
       "      <td>0.778898</td>\n",
       "      <td>0.778626</td>\n",
       "      <td>0.776151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression Model</td>\n",
       "      <td>0.778626</td>\n",
       "      <td>0.778898</td>\n",
       "      <td>0.778626</td>\n",
       "      <td>0.776151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomizedSearchCV Logistic Regression</td>\n",
       "      <td>0.778626</td>\n",
       "      <td>0.778898</td>\n",
       "      <td>0.778626</td>\n",
       "      <td>0.776151</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    model  Accuracy  Precision    Recall   \n",
       "0               Logistic Regression Model  0.778626   0.778898  0.778626  \\\n",
       "0               Logistic Regression Model  0.778626   0.778898  0.778626   \n",
       "0  RandomizedSearchCV Logistic Regression  0.778626   0.778898  0.778626   \n",
       "\n",
       "         F1  \n",
       "0  0.776151  \n",
       "0  0.776151  \n",
       "0  0.776151  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_preds = bestRecallTree.predict(X_test)\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"RandomizedSearchCV Logistic Regression\", \n",
    "                                                    'Accuracy': accuracy_score(y_test, model_preds) , \n",
    "                                                    'Precision': precision_score(y_test, model_preds, average='weighted') , \n",
    "                                                    'Recall': recall_score(y_test, model_preds, average='weighted'), \n",
    "                                                    'F1': f1_score(y_test, model_preds, average='weighted') }, index=[0])])\n",
    "performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb987104",
   "metadata": {},
   "source": [
    "# GridSearchCV Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d31fdf5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "[CV 1/5] END .....C=0.1, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END .....C=0.1, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END .....C=0.1, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END .....C=0.1, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END .....C=0.1, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.1, penalty=l1, solver=liblinear;, score=0.755 total time=   0.0s\n",
      "[CV 2/5] END C=0.1, penalty=l1, solver=liblinear;, score=0.653 total time=   0.0s\n",
      "[CV 3/5] END C=0.1, penalty=l1, solver=liblinear;, score=0.729 total time=   0.0s\n",
      "[CV 4/5] END C=0.1, penalty=l1, solver=liblinear;, score=0.583 total time=   0.0s\n",
      "[CV 5/5] END C=0.1, penalty=l1, solver=liblinear;, score=0.771 total time=   0.0s\n",
      "[CV 1/5] END ...C=0.1, penalty=l2, solver=lbfgs;, score=0.796 total time=   0.0s\n",
      "[CV 2/5] END ...C=0.1, penalty=l2, solver=lbfgs;, score=0.571 total time=   0.0s\n",
      "[CV 3/5] END ...C=0.1, penalty=l2, solver=lbfgs;, score=0.812 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END ...C=0.1, penalty=l2, solver=lbfgs;, score=0.708 total time=   0.0s\n",
      "[CV 5/5] END ...C=0.1, penalty=l2, solver=lbfgs;, score=0.812 total time=   0.0s\n",
      "[CV 1/5] END C=0.1, penalty=l2, solver=liblinear;, score=0.776 total time=   0.0s\n",
      "[CV 2/5] END C=0.1, penalty=l2, solver=liblinear;, score=0.653 total time=   0.0s\n",
      "[CV 3/5] END C=0.1, penalty=l2, solver=liblinear;, score=0.750 total time=   0.0s\n",
      "[CV 4/5] END C=0.1, penalty=l2, solver=liblinear;, score=0.625 total time=   0.0s\n",
      "[CV 5/5] END C=0.1, penalty=l2, solver=liblinear;, score=0.771 total time=   0.0s\n",
      "[CV 1/5] END ..C=0.1, penalty=lasso, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ..C=0.1, penalty=lasso, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ..C=0.1, penalty=lasso, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ..C=0.1, penalty=lasso, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ..C=0.1, penalty=lasso, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.1, penalty=lasso, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.1, penalty=lasso, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.1, penalty=lasso, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.1, penalty=lasso, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.1, penalty=lasso, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.1, penalty=elastic, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.1, penalty=elastic, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.1, penalty=elastic, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.1, penalty=elastic, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.1, penalty=elastic, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.1, penalty=elastic, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.1, penalty=elastic, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.1, penalty=elastic, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.1, penalty=elastic, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.1, penalty=elastic, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END .......C=1, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END .......C=1, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END .......C=1, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END .......C=1, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END .......C=1, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END .C=1, penalty=l1, solver=liblinear;, score=0.755 total time=   0.0s\n",
      "[CV 2/5] END .C=1, penalty=l1, solver=liblinear;, score=0.633 total time=   0.0s\n",
      "[CV 3/5] END .C=1, penalty=l1, solver=liblinear;, score=0.792 total time=   0.0s\n",
      "[CV 4/5] END .C=1, penalty=l1, solver=liblinear;, score=0.688 total time=   0.0s\n",
      "[CV 5/5] END .C=1, penalty=l1, solver=liblinear;, score=0.729 total time=   0.0s\n",
      "[CV 1/5] END .....C=1, penalty=l2, solver=lbfgs;, score=0.816 total time=   0.0s\n",
      "[CV 2/5] END .....C=1, penalty=l2, solver=lbfgs;, score=0.592 total time=   0.0s\n",
      "[CV 3/5] END .....C=1, penalty=l2, solver=lbfgs;, score=0.792 total time=   0.0s\n",
      "[CV 4/5] END .....C=1, penalty=l2, solver=lbfgs;, score=0.750 total time=   0.0s\n",
      "[CV 5/5] END .....C=1, penalty=l2, solver=lbfgs;, score=0.812 total time=   0.0s\n",
      "[CV 1/5] END .C=1, penalty=l2, solver=liblinear;, score=0.755 total time=   0.0s\n",
      "[CV 2/5] END .C=1, penalty=l2, solver=liblinear;, score=0.653 total time=   0.0s\n",
      "[CV 3/5] END .C=1, penalty=l2, solver=liblinear;, score=0.792 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END .C=1, penalty=l2, solver=liblinear;, score=0.667 total time=   0.0s\n",
      "[CV 5/5] END .C=1, penalty=l2, solver=liblinear;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END ....C=1, penalty=lasso, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ....C=1, penalty=lasso, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ....C=1, penalty=lasso, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ....C=1, penalty=lasso, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ....C=1, penalty=lasso, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1, penalty=lasso, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1, penalty=lasso, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1, penalty=lasso, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1, penalty=lasso, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1, penalty=lasso, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END ..C=1, penalty=elastic, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ..C=1, penalty=elastic, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ..C=1, penalty=elastic, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ..C=1, penalty=elastic, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ..C=1, penalty=elastic, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1, penalty=elastic, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1, penalty=elastic, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1, penalty=elastic, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1, penalty=elastic, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1, penalty=elastic, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END ......C=10, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ......C=10, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ......C=10, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ......C=10, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ......C=10, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=10, penalty=l1, solver=liblinear;, score=0.837 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=10, penalty=l1, solver=liblinear;, score=0.673 total time=   1.9s\n",
      "[CV 3/5] END C=10, penalty=l1, solver=liblinear;, score=0.792 total time=   0.0s\n",
      "[CV 4/5] END C=10, penalty=l1, solver=liblinear;, score=0.708 total time=   0.0s\n",
      "[CV 5/5] END C=10, penalty=l1, solver=liblinear;, score=0.771 total time=   0.0s\n",
      "[CV 1/5] END ....C=10, penalty=l2, solver=lbfgs;, score=0.837 total time=   0.0s\n",
      "[CV 2/5] END ....C=10, penalty=l2, solver=lbfgs;, score=0.612 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END ....C=10, penalty=l2, solver=lbfgs;, score=0.792 total time=   0.0s\n",
      "[CV 4/5] END ....C=10, penalty=l2, solver=lbfgs;, score=0.750 total time=   0.0s\n",
      "[CV 5/5] END ....C=10, penalty=l2, solver=lbfgs;, score=0.812 total time=   0.0s\n",
      "[CV 1/5] END C=10, penalty=l2, solver=liblinear;, score=0.776 total time=   0.0s\n",
      "[CV 2/5] END C=10, penalty=l2, solver=liblinear;, score=0.612 total time=   0.0s\n",
      "[CV 3/5] END C=10, penalty=l2, solver=liblinear;, score=0.792 total time=   0.0s\n",
      "[CV 4/5] END C=10, penalty=l2, solver=liblinear;, score=0.688 total time=   0.0s\n",
      "[CV 5/5] END C=10, penalty=l2, solver=liblinear;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END ...C=10, penalty=lasso, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ...C=10, penalty=lasso, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ...C=10, penalty=lasso, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ...C=10, penalty=lasso, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ...C=10, penalty=lasso, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=10, penalty=lasso, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=10, penalty=lasso, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=10, penalty=lasso, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=10, penalty=lasso, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=10, penalty=lasso, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END .C=10, penalty=elastic, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END .C=10, penalty=elastic, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END .C=10, penalty=elastic, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END .C=10, penalty=elastic, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END .C=10, penalty=elastic, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=10, penalty=elastic, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=10, penalty=elastic, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=10, penalty=elastic, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=10, penalty=elastic, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=10, penalty=elastic, solver=liblinear;, score=nan total time=   0.0s\n",
      "The best recall score is 0.7606292517006803\n",
      "... with parameters: {'C': 10, 'penalty': 'l2', 'solver': 'lbfgs'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "75 fits failed out of a total of 120.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1160, in fit\n",
      "    self._validate_params()\n",
      "  File \"C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'elasticnet', 'none' (deprecated), 'l1', 'l2'} or None. Got 'lasso' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1160, in fit\n",
      "    self._validate_params()\n",
      "  File \"C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'elasticnet', 'none' (deprecated), 'l1', 'l2'} or None. Got 'elastic' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan 0.69829932 0.74013605 0.71488095        nan        nan\n",
      "        nan        nan        nan 0.71921769 0.75246599 0.72329932\n",
      "        nan        nan        nan        nan        nan 0.75620748\n",
      " 0.76062925 0.72338435        nan        nan        nan        nan]\n",
      "  warnings.warn(\n",
      "C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"recall\"\n",
    "kfolds = 5\n",
    "param_grid = {'C': [0.1, 1, 10], \n",
    "              'solver' : [ 'lbfgs', 'liblinear'],\n",
    "              'penalty' : ['l1','l2','lasso','elastic']} \n",
    "  \n",
    "grid = GridSearchCV(LogisticRegression(), param_grid, refit = True, verbose = 3)\n",
    "  \n",
    "# fitting the model for grid search\n",
    "grid.fit(X_train, y_train)\n",
    "print(f\"The best {score_measure} score is {grid.best_score_}\")\n",
    "print(f\"... with parameters: {grid.best_params_}\")\n",
    "\n",
    "bestRecallTree = grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "710133b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression Model</td>\n",
       "      <td>0.778626</td>\n",
       "      <td>0.778898</td>\n",
       "      <td>0.778626</td>\n",
       "      <td>0.776151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression Model</td>\n",
       "      <td>0.778626</td>\n",
       "      <td>0.778898</td>\n",
       "      <td>0.778626</td>\n",
       "      <td>0.776151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomizedSearchCV Logistic Regression</td>\n",
       "      <td>0.778626</td>\n",
       "      <td>0.778898</td>\n",
       "      <td>0.778626</td>\n",
       "      <td>0.776151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GridSearchCV Logistic Regression</td>\n",
       "      <td>0.778626</td>\n",
       "      <td>0.778898</td>\n",
       "      <td>0.778626</td>\n",
       "      <td>0.776151</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    model  Accuracy  Precision    Recall   \n",
       "0               Logistic Regression Model  0.778626   0.778898  0.778626  \\\n",
       "0               Logistic Regression Model  0.778626   0.778898  0.778626   \n",
       "0  RandomizedSearchCV Logistic Regression  0.778626   0.778898  0.778626   \n",
       "0        GridSearchCV Logistic Regression  0.778626   0.778898  0.778626   \n",
       "\n",
       "         F1  \n",
       "0  0.776151  \n",
       "0  0.776151  \n",
       "0  0.776151  \n",
       "0  0.776151  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_preds = bestRecallTree.predict(X_test)\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"GridSearchCV Logistic Regression\", \n",
    "                                                    'Accuracy': accuracy_score(y_test, model_preds) , \n",
    "                                                    'Precision': precision_score(y_test, model_preds, average='weighted') , \n",
    "                                                    'Recall': recall_score(y_test, model_preds, average='weighted'), \n",
    "                                                    'F1': f1_score(y_test, model_preds, average='weighted') }, index=[0])])\n",
    "performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2eb76d",
   "metadata": {},
   "source": [
    "# SVM Classification model with Linear Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ee676741",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_lin_model = SVC(kernel=\"linear\", probability=True)\n",
    "_ = svm_lin_model.fit(X_train, np.ravel(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "25ea1b90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression Model</td>\n",
       "      <td>0.778626</td>\n",
       "      <td>0.778898</td>\n",
       "      <td>0.778626</td>\n",
       "      <td>0.776151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression Model</td>\n",
       "      <td>0.778626</td>\n",
       "      <td>0.778898</td>\n",
       "      <td>0.778626</td>\n",
       "      <td>0.776151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomizedSearchCV Logistic Regression</td>\n",
       "      <td>0.778626</td>\n",
       "      <td>0.778898</td>\n",
       "      <td>0.778626</td>\n",
       "      <td>0.776151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GridSearchCV Logistic Regression</td>\n",
       "      <td>0.778626</td>\n",
       "      <td>0.778898</td>\n",
       "      <td>0.778626</td>\n",
       "      <td>0.776151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM Classification model with Linear Kernel</td>\n",
       "      <td>0.847328</td>\n",
       "      <td>0.847498</td>\n",
       "      <td>0.847328</td>\n",
       "      <td>0.846258</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         model  Accuracy  Precision    Recall   \n",
       "0                    Logistic Regression Model  0.778626   0.778898  0.778626  \\\n",
       "0                    Logistic Regression Model  0.778626   0.778898  0.778626   \n",
       "0       RandomizedSearchCV Logistic Regression  0.778626   0.778898  0.778626   \n",
       "0             GridSearchCV Logistic Regression  0.778626   0.778898  0.778626   \n",
       "0  SVM Classification model with Linear Kernel  0.847328   0.847498  0.847328   \n",
       "\n",
       "         F1  \n",
       "0  0.776151  \n",
       "0  0.776151  \n",
       "0  0.776151  \n",
       "0  0.776151  \n",
       "0  0.846258  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_preds = svm_lin_model.predict(X_test)\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"SVM Classification model with Linear Kernel\", \n",
    "                                                    'Accuracy': accuracy_score(y_test, model_preds) , \n",
    "                                                    'Precision': precision_score(y_test, model_preds, average='weighted') , \n",
    "                                                    'Recall': recall_score(y_test, model_preds, average='weighted'), \n",
    "                                                    'F1': f1_score(y_test, model_preds, average='weighted') }, index=[0])])\n",
    "performance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b6e907",
   "metadata": {},
   "source": [
    "# SVM Classification model with rbf Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fba39e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_rbf_model = SVC(kernel=\"rbf\", C=10, gamma='scale', probability=True)\n",
    "_ = svm_rbf_model.fit(X_train, np.ravel(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "884d69fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression Model</td>\n",
       "      <td>0.778626</td>\n",
       "      <td>0.778898</td>\n",
       "      <td>0.778626</td>\n",
       "      <td>0.776151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression Model</td>\n",
       "      <td>0.778626</td>\n",
       "      <td>0.778898</td>\n",
       "      <td>0.778626</td>\n",
       "      <td>0.776151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomizedSearchCV Logistic Regression</td>\n",
       "      <td>0.778626</td>\n",
       "      <td>0.778898</td>\n",
       "      <td>0.778626</td>\n",
       "      <td>0.776151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GridSearchCV Logistic Regression</td>\n",
       "      <td>0.778626</td>\n",
       "      <td>0.778898</td>\n",
       "      <td>0.778626</td>\n",
       "      <td>0.776151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM Classification model with Linear Kernel</td>\n",
       "      <td>0.847328</td>\n",
       "      <td>0.847498</td>\n",
       "      <td>0.847328</td>\n",
       "      <td>0.846258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM Classification model with rbf Kernel</td>\n",
       "      <td>0.702290</td>\n",
       "      <td>0.702525</td>\n",
       "      <td>0.702290</td>\n",
       "      <td>0.700828</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         model  Accuracy  Precision    Recall   \n",
       "0                    Logistic Regression Model  0.778626   0.778898  0.778626  \\\n",
       "0                    Logistic Regression Model  0.778626   0.778898  0.778626   \n",
       "0       RandomizedSearchCV Logistic Regression  0.778626   0.778898  0.778626   \n",
       "0             GridSearchCV Logistic Regression  0.778626   0.778898  0.778626   \n",
       "0  SVM Classification model with Linear Kernel  0.847328   0.847498  0.847328   \n",
       "0     SVM Classification model with rbf Kernel  0.702290   0.702525  0.702290   \n",
       "\n",
       "         F1  \n",
       "0  0.776151  \n",
       "0  0.776151  \n",
       "0  0.776151  \n",
       "0  0.776151  \n",
       "0  0.846258  \n",
       "0  0.700828  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_preds = svm_rbf_model.predict(X_test)\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"SVM Classification model with rbf Kernel\", \n",
    "                                                    'Accuracy': accuracy_score(y_test, model_preds) , \n",
    "                                                    'Precision': precision_score(y_test, model_preds, average='weighted') , \n",
    "                                                    'Recall': recall_score(y_test, model_preds, average='weighted'), \n",
    "                                                    'F1': f1_score(y_test, model_preds, average='weighted') }, index=[0])])\n",
    "performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60fafcf6",
   "metadata": {},
   "source": [
    "## SVM Classification model with Polynomial Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1395b641",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_poly_model = SVC(kernel=\"poly\", degree=3, coef0=1, C=10, probability=True)\n",
    "_ = svm_poly_model.fit(X_train, np.ravel(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0b0fc30e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression Model</td>\n",
       "      <td>0.778626</td>\n",
       "      <td>0.778898</td>\n",
       "      <td>0.778626</td>\n",
       "      <td>0.776151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression Model</td>\n",
       "      <td>0.778626</td>\n",
       "      <td>0.778898</td>\n",
       "      <td>0.778626</td>\n",
       "      <td>0.776151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomizedSearchCV Logistic Regression</td>\n",
       "      <td>0.778626</td>\n",
       "      <td>0.778898</td>\n",
       "      <td>0.778626</td>\n",
       "      <td>0.776151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GridSearchCV Logistic Regression</td>\n",
       "      <td>0.778626</td>\n",
       "      <td>0.778898</td>\n",
       "      <td>0.778626</td>\n",
       "      <td>0.776151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM Classification model with Linear Kernel</td>\n",
       "      <td>0.847328</td>\n",
       "      <td>0.847498</td>\n",
       "      <td>0.847328</td>\n",
       "      <td>0.846258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM Classification model with rbf Kernel</td>\n",
       "      <td>0.702290</td>\n",
       "      <td>0.702525</td>\n",
       "      <td>0.702290</td>\n",
       "      <td>0.700828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM Classification model with Polynomial Kernel</td>\n",
       "      <td>0.793893</td>\n",
       "      <td>0.797295</td>\n",
       "      <td>0.793893</td>\n",
       "      <td>0.792514</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             model  Accuracy  Precision   \n",
       "0                        Logistic Regression Model  0.778626   0.778898  \\\n",
       "0                        Logistic Regression Model  0.778626   0.778898   \n",
       "0           RandomizedSearchCV Logistic Regression  0.778626   0.778898   \n",
       "0                 GridSearchCV Logistic Regression  0.778626   0.778898   \n",
       "0      SVM Classification model with Linear Kernel  0.847328   0.847498   \n",
       "0         SVM Classification model with rbf Kernel  0.702290   0.702525   \n",
       "0  SVM Classification model with Polynomial Kernel  0.793893   0.797295   \n",
       "\n",
       "     Recall        F1  \n",
       "0  0.778626  0.776151  \n",
       "0  0.778626  0.776151  \n",
       "0  0.778626  0.776151  \n",
       "0  0.778626  0.776151  \n",
       "0  0.847328  0.846258  \n",
       "0  0.702290  0.700828  \n",
       "0  0.793893  0.792514  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_preds = svm_poly_model.predict(X_test)\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"SVM Classification model with Polynomial Kernel\", \n",
    "                                                    'Accuracy': accuracy_score(y_test, model_preds) , \n",
    "                                                    'Precision': precision_score(y_test, model_preds, average='weighted') , \n",
    "                                                    'Recall': recall_score(y_test, model_preds, average='weighted'), \n",
    "                                                    'F1': f1_score(y_test, model_preds, average='weighted') }, index=[0])])\n",
    "performance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aadeee98",
   "metadata": {},
   "source": [
    "# Decision tree model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "51f8c745",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = DecisionTreeClassifier()\n",
    "classifier = classifier.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a426663c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression Model</td>\n",
       "      <td>0.778626</td>\n",
       "      <td>0.778898</td>\n",
       "      <td>0.778626</td>\n",
       "      <td>0.776151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression Model</td>\n",
       "      <td>0.778626</td>\n",
       "      <td>0.778898</td>\n",
       "      <td>0.778626</td>\n",
       "      <td>0.776151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomizedSearchCV Logistic Regression</td>\n",
       "      <td>0.778626</td>\n",
       "      <td>0.778898</td>\n",
       "      <td>0.778626</td>\n",
       "      <td>0.776151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GridSearchCV Logistic Regression</td>\n",
       "      <td>0.778626</td>\n",
       "      <td>0.778898</td>\n",
       "      <td>0.778626</td>\n",
       "      <td>0.776151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM Classification model with Linear Kernel</td>\n",
       "      <td>0.847328</td>\n",
       "      <td>0.847498</td>\n",
       "      <td>0.847328</td>\n",
       "      <td>0.846258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM Classification model with rbf Kernel</td>\n",
       "      <td>0.702290</td>\n",
       "      <td>0.702525</td>\n",
       "      <td>0.702290</td>\n",
       "      <td>0.700828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM Classification model with Polynomial Kernel</td>\n",
       "      <td>0.793893</td>\n",
       "      <td>0.797295</td>\n",
       "      <td>0.793893</td>\n",
       "      <td>0.792514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision tree model</td>\n",
       "      <td>0.809160</td>\n",
       "      <td>0.811874</td>\n",
       "      <td>0.809160</td>\n",
       "      <td>0.809896</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             model  Accuracy  Precision   \n",
       "0                        Logistic Regression Model  0.778626   0.778898  \\\n",
       "0                        Logistic Regression Model  0.778626   0.778898   \n",
       "0           RandomizedSearchCV Logistic Regression  0.778626   0.778898   \n",
       "0                 GridSearchCV Logistic Regression  0.778626   0.778898   \n",
       "0      SVM Classification model with Linear Kernel  0.847328   0.847498   \n",
       "0         SVM Classification model with rbf Kernel  0.702290   0.702525   \n",
       "0  SVM Classification model with Polynomial Kernel  0.793893   0.797295   \n",
       "0                              Decision tree model  0.809160   0.811874   \n",
       "\n",
       "     Recall        F1  \n",
       "0  0.778626  0.776151  \n",
       "0  0.778626  0.776151  \n",
       "0  0.778626  0.776151  \n",
       "0  0.778626  0.776151  \n",
       "0  0.847328  0.846258  \n",
       "0  0.702290  0.700828  \n",
       "0  0.793893  0.792514  \n",
       "0  0.809160  0.809896  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_preds = classifier.predict(X_test)\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"Decision tree model\", \n",
    "                                                    'Accuracy': accuracy_score(y_test, model_preds) , \n",
    "                                                    'Precision': precision_score(y_test, model_preds, average='weighted') , \n",
    "                                                    'Recall': recall_score(y_test, model_preds, average='weighted'), \n",
    "                                                    'F1': f1_score(y_test, model_preds, average='weighted') }, index=[0])])\n",
    "performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0693336c",
   "metadata": {},
   "source": [
    "# Decision tree model using the randomsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d769af9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 500 candidates, totalling 2500 fits\n",
      "The best recall score is nan\n",
      "... with parameters: {'min_samples_split': 46, 'min_samples_leaf': 10, 'min_impurity_decrease': 0.0086, 'max_leaf_nodes': 68, 'max_depth': 21, 'criterion': 'entropy'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "55 fits failed out of a total of 2500.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "55 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 889, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 177, in fit\n",
      "    self._validate_params()\n",
      "  File \"C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of DecisionTreeClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n",
      "C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the train scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"recall\"\n",
    "kfolds = 5\n",
    "\n",
    "param_grid = {\n",
    "    'min_samples_split': np.arange(1,60),  \n",
    "    'min_samples_leaf': np.arange(1,50),\n",
    "    'min_impurity_decrease': np.arange(0.0001, 0.01, 0.0005),\n",
    "    'max_leaf_nodes': np.arange(5, 200), \n",
    "    'max_depth': np.arange(1,50), \n",
    "    'criterion': ['entropy', 'gini'],\n",
    "}\n",
    "\n",
    "dtree = DecisionTreeClassifier()\n",
    "rand_search = RandomizedSearchCV(estimator = dtree, param_distributions=param_grid, cv=kfolds, n_iter=500,\n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1, return_train_score=True)\n",
    "\n",
    "_ = rand_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"The best {score_measure} score is {rand_search.best_score_}\")\n",
    "print(f\"... with parameters: {rand_search.best_params_}\")\n",
    "\n",
    "bestRecallTree = rand_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a299683a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression Model</td>\n",
       "      <td>0.778626</td>\n",
       "      <td>0.778898</td>\n",
       "      <td>0.778626</td>\n",
       "      <td>0.776151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression Model</td>\n",
       "      <td>0.778626</td>\n",
       "      <td>0.778898</td>\n",
       "      <td>0.778626</td>\n",
       "      <td>0.776151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomizedSearchCV Logistic Regression</td>\n",
       "      <td>0.778626</td>\n",
       "      <td>0.778898</td>\n",
       "      <td>0.778626</td>\n",
       "      <td>0.776151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GridSearchCV Logistic Regression</td>\n",
       "      <td>0.778626</td>\n",
       "      <td>0.778898</td>\n",
       "      <td>0.778626</td>\n",
       "      <td>0.776151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM Classification model with Linear Kernel</td>\n",
       "      <td>0.847328</td>\n",
       "      <td>0.847498</td>\n",
       "      <td>0.847328</td>\n",
       "      <td>0.846258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM Classification model with rbf Kernel</td>\n",
       "      <td>0.702290</td>\n",
       "      <td>0.702525</td>\n",
       "      <td>0.702290</td>\n",
       "      <td>0.700828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM Classification model with Polynomial Kernel</td>\n",
       "      <td>0.793893</td>\n",
       "      <td>0.797295</td>\n",
       "      <td>0.793893</td>\n",
       "      <td>0.792514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision tree model</td>\n",
       "      <td>0.809160</td>\n",
       "      <td>0.811874</td>\n",
       "      <td>0.809160</td>\n",
       "      <td>0.809896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision tree model using the randomsearch</td>\n",
       "      <td>0.854962</td>\n",
       "      <td>0.860624</td>\n",
       "      <td>0.854962</td>\n",
       "      <td>0.855194</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             model  Accuracy  Precision   \n",
       "0                        Logistic Regression Model  0.778626   0.778898  \\\n",
       "0                        Logistic Regression Model  0.778626   0.778898   \n",
       "0           RandomizedSearchCV Logistic Regression  0.778626   0.778898   \n",
       "0                 GridSearchCV Logistic Regression  0.778626   0.778898   \n",
       "0      SVM Classification model with Linear Kernel  0.847328   0.847498   \n",
       "0         SVM Classification model with rbf Kernel  0.702290   0.702525   \n",
       "0  SVM Classification model with Polynomial Kernel  0.793893   0.797295   \n",
       "0                              Decision tree model  0.809160   0.811874   \n",
       "0       Decision tree model using the randomsearch  0.854962   0.860624   \n",
       "\n",
       "     Recall        F1  \n",
       "0  0.778626  0.776151  \n",
       "0  0.778626  0.776151  \n",
       "0  0.778626  0.776151  \n",
       "0  0.778626  0.776151  \n",
       "0  0.847328  0.846258  \n",
       "0  0.702290  0.700828  \n",
       "0  0.793893  0.792514  \n",
       "0  0.809160  0.809896  \n",
       "0  0.854962  0.855194  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_preds = bestRecallTree.predict(X_test)\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"Decision tree model using the randomsearch\", \n",
    "                                                    'Accuracy': accuracy_score(y_test, model_preds) , \n",
    "                                                    'Precision': precision_score(y_test, model_preds, average='weighted') , \n",
    "                                                    'Recall': recall_score(y_test, model_preds, average='weighted'), \n",
    "                                                    'F1': f1_score(y_test, model_preds, average='weighted') }, index=[0])])\n",
    "performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d465efe",
   "metadata": {},
   "source": [
    "# Decision tree model using the Gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "266feb2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3024 candidates, totalling 15120 fits\n",
      "The best recall score is nan\n",
      "... with parameters: {'criterion': 'entropy', 'max_depth': 15, 'max_leaf_nodes': 162, 'min_impurity_decrease': 0.0048, 'min_samples_leaf': 1, 'min_samples_split': 7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [nan nan nan ... nan nan nan]\n",
      "  warnings.warn(\n",
      "C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the train scores are non-finite: [nan nan nan ... nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"recall\"\n",
    "kfolds = 5\n",
    "\n",
    "param_grid = {\n",
    "    'min_samples_split': np.arange(7,10),  \n",
    "    'min_samples_leaf': np.arange(1,5),\n",
    "    'min_impurity_decrease': np.arange(0.0048, 0.0054, 0.0001),\n",
    "    'max_leaf_nodes': np.arange(162,168), \n",
    "    'max_depth': np.arange(15,21), \n",
    "    'criterion': ['entropy'],\n",
    "}\n",
    "\n",
    "dtree = DecisionTreeClassifier()\n",
    "grid_search = GridSearchCV(estimator = dtree, param_grid=param_grid, cv=kfolds, \n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"The best {score_measure} score is {grid_search.best_score_}\")\n",
    "print(f\"... with parameters: {grid_search.best_params_}\")\n",
    "\n",
    "bestRecallTree = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f7128fab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression Model</td>\n",
       "      <td>0.778626</td>\n",
       "      <td>0.778898</td>\n",
       "      <td>0.778626</td>\n",
       "      <td>0.776151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression Model</td>\n",
       "      <td>0.778626</td>\n",
       "      <td>0.778898</td>\n",
       "      <td>0.778626</td>\n",
       "      <td>0.776151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomizedSearchCV Logistic Regression</td>\n",
       "      <td>0.778626</td>\n",
       "      <td>0.778898</td>\n",
       "      <td>0.778626</td>\n",
       "      <td>0.776151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GridSearchCV Logistic Regression</td>\n",
       "      <td>0.778626</td>\n",
       "      <td>0.778898</td>\n",
       "      <td>0.778626</td>\n",
       "      <td>0.776151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM Classification model with Linear Kernel</td>\n",
       "      <td>0.847328</td>\n",
       "      <td>0.847498</td>\n",
       "      <td>0.847328</td>\n",
       "      <td>0.846258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM Classification model with rbf Kernel</td>\n",
       "      <td>0.702290</td>\n",
       "      <td>0.702525</td>\n",
       "      <td>0.702290</td>\n",
       "      <td>0.700828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM Classification model with Polynomial Kernel</td>\n",
       "      <td>0.793893</td>\n",
       "      <td>0.797295</td>\n",
       "      <td>0.793893</td>\n",
       "      <td>0.792514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision tree model</td>\n",
       "      <td>0.809160</td>\n",
       "      <td>0.811874</td>\n",
       "      <td>0.809160</td>\n",
       "      <td>0.809896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision tree model using the randomsearch</td>\n",
       "      <td>0.854962</td>\n",
       "      <td>0.860624</td>\n",
       "      <td>0.854962</td>\n",
       "      <td>0.855194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision tree model using the Gridsearch</td>\n",
       "      <td>0.801527</td>\n",
       "      <td>0.806714</td>\n",
       "      <td>0.801527</td>\n",
       "      <td>0.803087</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             model  Accuracy  Precision   \n",
       "0                        Logistic Regression Model  0.778626   0.778898  \\\n",
       "0                        Logistic Regression Model  0.778626   0.778898   \n",
       "0           RandomizedSearchCV Logistic Regression  0.778626   0.778898   \n",
       "0                 GridSearchCV Logistic Regression  0.778626   0.778898   \n",
       "0      SVM Classification model with Linear Kernel  0.847328   0.847498   \n",
       "0         SVM Classification model with rbf Kernel  0.702290   0.702525   \n",
       "0  SVM Classification model with Polynomial Kernel  0.793893   0.797295   \n",
       "0                              Decision tree model  0.809160   0.811874   \n",
       "0       Decision tree model using the randomsearch  0.854962   0.860624   \n",
       "0         Decision tree model using the Gridsearch  0.801527   0.806714   \n",
       "\n",
       "     Recall        F1  \n",
       "0  0.778626  0.776151  \n",
       "0  0.778626  0.776151  \n",
       "0  0.778626  0.776151  \n",
       "0  0.778626  0.776151  \n",
       "0  0.847328  0.846258  \n",
       "0  0.702290  0.700828  \n",
       "0  0.793893  0.792514  \n",
       "0  0.809160  0.809896  \n",
       "0  0.854962  0.855194  \n",
       "0  0.801527  0.803087  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_preds = bestRecallTree.predict(X_test)\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"Decision tree model using the Gridsearch\", \n",
    "                                                    'Accuracy': accuracy_score(y_test, model_preds) , \n",
    "                                                    'Precision': precision_score(y_test, model_preds, average='weighted') , \n",
    "                                                    'Recall': recall_score(y_test, model_preds, average='weighted'), \n",
    "                                                    'F1': f1_score(y_test, model_preds, average='weighted') }, index=[0])])\n",
    "performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "127e7550",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM Classification model with rbf Kernel</td>\n",
       "      <td>0.702290</td>\n",
       "      <td>0.702525</td>\n",
       "      <td>0.702290</td>\n",
       "      <td>0.700828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression Model</td>\n",
       "      <td>0.778626</td>\n",
       "      <td>0.778898</td>\n",
       "      <td>0.778626</td>\n",
       "      <td>0.776151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression Model</td>\n",
       "      <td>0.778626</td>\n",
       "      <td>0.778898</td>\n",
       "      <td>0.778626</td>\n",
       "      <td>0.776151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomizedSearchCV Logistic Regression</td>\n",
       "      <td>0.778626</td>\n",
       "      <td>0.778898</td>\n",
       "      <td>0.778626</td>\n",
       "      <td>0.776151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GridSearchCV Logistic Regression</td>\n",
       "      <td>0.778626</td>\n",
       "      <td>0.778898</td>\n",
       "      <td>0.778626</td>\n",
       "      <td>0.776151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM Classification model with Polynomial Kernel</td>\n",
       "      <td>0.793893</td>\n",
       "      <td>0.797295</td>\n",
       "      <td>0.793893</td>\n",
       "      <td>0.792514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision tree model using the Gridsearch</td>\n",
       "      <td>0.801527</td>\n",
       "      <td>0.806714</td>\n",
       "      <td>0.801527</td>\n",
       "      <td>0.803087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision tree model</td>\n",
       "      <td>0.809160</td>\n",
       "      <td>0.811874</td>\n",
       "      <td>0.809160</td>\n",
       "      <td>0.809896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM Classification model with Linear Kernel</td>\n",
       "      <td>0.847328</td>\n",
       "      <td>0.847498</td>\n",
       "      <td>0.847328</td>\n",
       "      <td>0.846258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision tree model using the randomsearch</td>\n",
       "      <td>0.854962</td>\n",
       "      <td>0.860624</td>\n",
       "      <td>0.854962</td>\n",
       "      <td>0.855194</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             model  Accuracy  Precision   \n",
       "0         SVM Classification model with rbf Kernel  0.702290   0.702525  \\\n",
       "0                        Logistic Regression Model  0.778626   0.778898   \n",
       "0                        Logistic Regression Model  0.778626   0.778898   \n",
       "0           RandomizedSearchCV Logistic Regression  0.778626   0.778898   \n",
       "0                 GridSearchCV Logistic Regression  0.778626   0.778898   \n",
       "0  SVM Classification model with Polynomial Kernel  0.793893   0.797295   \n",
       "0         Decision tree model using the Gridsearch  0.801527   0.806714   \n",
       "0                              Decision tree model  0.809160   0.811874   \n",
       "0      SVM Classification model with Linear Kernel  0.847328   0.847498   \n",
       "0       Decision tree model using the randomsearch  0.854962   0.860624   \n",
       "\n",
       "     Recall        F1  \n",
       "0  0.702290  0.700828  \n",
       "0  0.778626  0.776151  \n",
       "0  0.778626  0.776151  \n",
       "0  0.778626  0.776151  \n",
       "0  0.778626  0.776151  \n",
       "0  0.793893  0.792514  \n",
       "0  0.801527  0.803087  \n",
       "0  0.809160  0.809896  \n",
       "0  0.847328  0.846258  \n",
       "0  0.854962  0.855194  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance.sort_values(by=['Recall'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce7c71b",
   "metadata": {},
   "source": [
    "Using a decision boundary that optimizes the margin between the classes, the widely used classification algorithm SVM with a linear kernel divides data points into distinct classes. The sort of data, the selection of hyperparameters, and the size of the training set are just a few variables that can have an impact on how well an SVM with a linear kernel performs.\n",
    "\n",
    "When the data is linearly separablethat is, when a hyperplane exists that can completely separate the data points into various classesSVMs with linear kernels are generally known to perform well. When this is the case, SVMs are able to produce results with high recall and accuracy rates, which makes them a common option for classification tasks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5258ddd",
   "metadata": {},
   "source": [
    "Decision tree model using the randomsearch is considered to be the best fitting model with a recall value of 85.4%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5f6704",
   "metadata": {},
   "source": [
    "## Neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "933ca4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "139cd278",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1098: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 739 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "ann = MLPClassifier(hidden_layer_sizes=(40,20), solver='adam', max_iter=200)\n",
    "_ = ann.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d7ffb3aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = ann.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b56c41d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Salary\n",
       "0.0       39\n",
       "2.0       32\n",
       "3.0       32\n",
       "1.0       28\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ea2a6d17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 2, 0, 2, 0, 3, 3, 1, 0, 1, 0, 2, 2, 0, 0, 3, 1, 3, 0, 1, 0,\n",
       "       2, 3, 3, 3, 0, 3, 0, 0, 3, 3, 0, 3, 0, 3, 3, 0, 2, 3, 1, 0, 2, 3,\n",
       "       1, 3, 3, 0, 2, 3, 0, 2, 3, 0, 0, 2, 2, 1, 0, 3, 3, 1, 0, 0, 3, 2,\n",
       "       0, 1, 2, 0, 3, 3, 1, 3, 0, 0, 2, 0, 0, 1, 3, 3, 3, 0, 0, 2, 2, 2,\n",
       "       2, 3, 3, 3, 1, 3, 1, 0, 2, 2, 1, 2, 3, 3, 1, 1, 1, 2, 2, 0, 0, 0,\n",
       "       1, 0, 3, 1, 2, 1, 3, 1, 0, 0, 3, 1, 0, 1, 2, 1, 1, 1, 1, 3, 2],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dc3a657c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "eb236ec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.87      0.86        39\n",
      "         1.0       0.63      0.61      0.62        28\n",
      "         2.0       0.77      0.62      0.69        32\n",
      "         3.0       0.79      0.94      0.86        32\n",
      "\n",
      "    accuracy                           0.77       131\n",
      "   macro avg       0.76      0.76      0.76       131\n",
      "weighted avg       0.77      0.77      0.77       131\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12639003",
   "metadata": {},
   "source": [
    "## Nueral Network model With RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6e5348f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n",
      "C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the train scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n",
      "C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1098: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'solver': 'sgd', 'max_iter': 5000, 'learning_rate_init': 0.001, 'learning_rate': 'constant', 'hidden_layer_sizes': (40, 40, 40), 'alpha': 0.7, 'activation': 'relu'}\n",
      "CPU times: total: 1.48 s\n",
      "Wall time: 43.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "score_measure = \"recall\"\n",
    "kfolds = 5\n",
    "\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(40,20),(40,40,40)],\n",
    "    'activation': ['tanh', 'relu'],\n",
    "    'solver': ['adam', 'sgd'],\n",
    "    'alpha': [0, .2, .5, .7, 1],\n",
    "    'learning_rate': ['constant', 'invscaling', 'adaptive'],\n",
    "    'learning_rate_init': [0.001, 0.01, 0.1, 0.2, 0.5],\n",
    "    'max_iter': [5000]\n",
    "}\n",
    "\n",
    "ann = MLPClassifier()\n",
    "grid_search = RandomizedSearchCV(estimator = ann, param_distributions=param_grid, cv=kfolds, n_iter=100,\n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = grid_search.fit(X_train, y_train)\n",
    "\n",
    "bestRecallTree = grid_search.best_estimator_\n",
    "\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a01d076c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.87      0.86        39\n",
      "         1.0       0.47      0.25      0.33        28\n",
      "         2.0       0.52      0.44      0.47        32\n",
      "         3.0       0.63      0.97      0.77        32\n",
      "\n",
      "    accuracy                           0.66       131\n",
      "   macro avg       0.62      0.63      0.61       131\n",
      "weighted avg       0.63      0.66      0.63       131\n",
      "\n",
      "CPU times: total: 15.6 ms\n",
      "Wall time: 31.2 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = bestRecallTree.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb04b2b",
   "metadata": {},
   "source": [
    "## Neural Network model With GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "23855d59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n",
      "C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the train scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n",
      "C:\\Users\\dkrre\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1098: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'relu', 'alpha': 0.3, 'hidden_layer_sizes': (40, 40, 40), 'learning_rate': 'adaptive', 'learning_rate_init': 0.005, 'max_iter': 5000, 'solver': 'adam'}\n",
      "CPU times: total: 2.2 s\n",
      "Wall time: 45.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "score_measure = \"recall\"\n",
    "kfolds = 5\n",
    "\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [ (40,40,40), (50,40,20), (50,50,50), (80,)],\n",
    "    'activation': ['relu','tanh'],\n",
    "    'solver': ['adam'],\n",
    "    'alpha': [.3, .5, 1],\n",
    "    'learning_rate': ['adaptive', 'invscaling'],\n",
    "    'learning_rate_init': [0.005, 0.01, 0.15],\n",
    "    'max_iter': [5000]\n",
    "}\n",
    "\n",
    "ann = MLPClassifier()\n",
    "grid_search = GridSearchCV(estimator = ann, param_grid=param_grid, cv=kfolds, \n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = grid_search.fit(X_train, y_train)\n",
    "\n",
    "bestRecallTree = grid_search.best_estimator_\n",
    "\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "eb4789c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.92      0.91        39\n",
      "         1.0       0.75      0.32      0.45        28\n",
      "         2.0       0.58      0.69      0.63        32\n",
      "         3.0       0.76      0.97      0.85        32\n",
      "\n",
      "    accuracy                           0.75       131\n",
      "   macro avg       0.75      0.73      0.71       131\n",
      "weighted avg       0.75      0.75      0.73       131\n",
      "\n",
      "CPU times: total: 31.2 ms\n",
      "Wall time: 18.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = bestRecallTree.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4f344a10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(131, 5)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "95379716",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Salary\n",
       "1         73\n",
       "2         59\n",
       "0         57\n",
       "3         53\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17691e95",
   "metadata": {},
   "source": [
    "## Using Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00e59fa",
   "metadata": {},
   "source": [
    "## Deep Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "17765eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "9a7bf011",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "np.random.seed(1)\n",
    "tf.random.set_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "724db420",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(131, 5)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "a9a6b7fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Salary\n",
       "0.0       39\n",
       "2.0       32\n",
       "3.0       32\n",
       "1.0       28\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "cc6f57b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 78.1 ms\n",
      "Wall time: 94.3 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# create model stucture\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Input(5))\n",
    "model.add(keras.layers.Dense(50, activation='relu'))\n",
    "model.add(keras.layers.Dense(50, activation='relu'))\n",
    "model.add(keras.layers.Dense(50, activation='relu'))\n",
    "model.add(keras.layers.Dense(4, activation='softmax')) # final layer, 10 categories\n",
    "\n",
    "\n",
    "# compile\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# if you want to overide the defaults for the optimizer....\n",
    "#adam = keras.optimizers.Adam(learning_rate=0.01)\n",
    "#model.compile(loss='sparse_categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "70fa02cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 0.8860 - accuracy: 0.6364 - val_loss: 0.8983 - val_accuracy: 0.6412\n",
      "Epoch 2/25\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.8689 - accuracy: 0.6405 - val_loss: 0.8847 - val_accuracy: 0.6565\n",
      "Epoch 3/25\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.8536 - accuracy: 0.6446 - val_loss: 0.8683 - val_accuracy: 0.6489\n",
      "Epoch 4/25\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.8387 - accuracy: 0.6653 - val_loss: 0.8495 - val_accuracy: 0.6641\n",
      "Epoch 5/25\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.8207 - accuracy: 0.6570 - val_loss: 0.8272 - val_accuracy: 0.6870\n",
      "Epoch 6/25\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.8181 - accuracy: 0.6364 - val_loss: 0.8211 - val_accuracy: 0.6565\n",
      "Epoch 7/25\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.8098 - accuracy: 0.6529 - val_loss: 0.8200 - val_accuracy: 0.6641\n",
      "Epoch 8/25\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.7956 - accuracy: 0.6653 - val_loss: 0.8090 - val_accuracy: 0.6565\n",
      "Epoch 9/25\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.8114 - accuracy: 0.5950 - val_loss: 0.8017 - val_accuracy: 0.6794\n",
      "Epoch 10/25\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.7801 - accuracy: 0.6446 - val_loss: 0.8107 - val_accuracy: 0.6718\n",
      "Epoch 11/25\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.8046 - accuracy: 0.6240 - val_loss: 0.7857 - val_accuracy: 0.6794\n",
      "Epoch 12/25\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.7829 - accuracy: 0.6322 - val_loss: 0.7667 - val_accuracy: 0.6641\n",
      "Epoch 13/25\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.7635 - accuracy: 0.6612 - val_loss: 0.7647 - val_accuracy: 0.6489\n",
      "Epoch 14/25\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.7596 - accuracy: 0.6860 - val_loss: 0.7654 - val_accuracy: 0.6870\n",
      "Epoch 15/25\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.7497 - accuracy: 0.6694 - val_loss: 0.7571 - val_accuracy: 0.7023\n",
      "Epoch 16/25\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.7453 - accuracy: 0.6612 - val_loss: 0.7506 - val_accuracy: 0.6794\n",
      "Epoch 17/25\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.7402 - accuracy: 0.6777 - val_loss: 0.7429 - val_accuracy: 0.6565\n",
      "Epoch 18/25\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.7281 - accuracy: 0.7107 - val_loss: 0.7220 - val_accuracy: 0.7099\n",
      "Epoch 19/25\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.7329 - accuracy: 0.6860 - val_loss: 0.7122 - val_accuracy: 0.7099\n",
      "Epoch 20/25\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.7181 - accuracy: 0.7107 - val_loss: 0.7189 - val_accuracy: 0.6794\n",
      "Epoch 21/25\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.7124 - accuracy: 0.7025 - val_loss: 0.7369 - val_accuracy: 0.6794\n",
      "Epoch 22/25\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.7115 - accuracy: 0.7066 - val_loss: 0.7210 - val_accuracy: 0.7176\n",
      "Epoch 23/25\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.7035 - accuracy: 0.7066 - val_loss: 0.7081 - val_accuracy: 0.7099\n",
      "Epoch 24/25\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.6952 - accuracy: 0.7190 - val_loss: 0.6837 - val_accuracy: 0.7328\n",
      "Epoch 25/25\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.6892 - accuracy: 0.7231 - val_loss: 0.6901 - val_accuracy: 0.7252\n",
      "CPU times: total: 1 s\n",
      "Wall time: 2.34 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# fit the model\n",
    "history = model.fit(X_train, y_train, \n",
    "                    validation_data=(X_test, y_test), \n",
    "                    epochs=25, batch_size=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "18b77e50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6900591850280762, 0.7251908183097839]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the model\n",
    "\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "scores\n",
    "# In results, first is loss, second is accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "fe496ff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.69\n",
      "accuracy: 72.52%\n"
     ]
    }
   ],
   "source": [
    "# let's format this into a better output...\n",
    "\n",
    "print(\"%s: %.2f\" % (model.metrics_names[0], scores[0]))\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fcf479d",
   "metadata": {},
   "source": [
    "## Wide and Deep Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "d2e69a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the model: for multi-class\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "\n",
    "model.add(keras.layers.Input(shape=5))\n",
    "model.add(keras.layers.Dense(100, activation='relu'))\n",
    "model.add(keras.layers.Dense(100, activation='relu'))\n",
    "model.add(keras.layers.Dense(100, activation='relu'))\n",
    "model.add(keras.layers.Dense(4, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "79487f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "\n",
    "#Optimizer:\n",
    "adam = keras.optimizers.Adam(learning_rate=0.01)\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=adam, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "16beed2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 0.5369 - accuracy: 0.7314 - val_loss: 0.7051 - val_accuracy: 0.6794\n",
      "Epoch 2/25\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.5612 - accuracy: 0.7149 - val_loss: 0.5509 - val_accuracy: 0.7405\n",
      "Epoch 3/25\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.5506 - accuracy: 0.7066 - val_loss: 0.5286 - val_accuracy: 0.7328\n",
      "Epoch 4/25\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.5280 - accuracy: 0.7521 - val_loss: 0.4992 - val_accuracy: 0.7786\n",
      "Epoch 5/25\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.4913 - accuracy: 0.7603 - val_loss: 0.4787 - val_accuracy: 0.7710\n",
      "Epoch 6/25\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.4703 - accuracy: 0.7934 - val_loss: 0.4606 - val_accuracy: 0.7557\n",
      "Epoch 7/25\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.4903 - accuracy: 0.7645 - val_loss: 0.4723 - val_accuracy: 0.8397\n",
      "Epoch 8/25\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.4597 - accuracy: 0.7851 - val_loss: 0.5600 - val_accuracy: 0.7252\n",
      "Epoch 9/25\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.5384 - accuracy: 0.7397 - val_loss: 0.5801 - val_accuracy: 0.6947\n",
      "Epoch 10/25\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.5948 - accuracy: 0.7025 - val_loss: 0.5440 - val_accuracy: 0.7328\n",
      "Epoch 11/25\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.5139 - accuracy: 0.7686 - val_loss: 0.4523 - val_accuracy: 0.7939\n",
      "Epoch 12/25\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.4840 - accuracy: 0.7645 - val_loss: 0.5412 - val_accuracy: 0.7328\n",
      "Epoch 13/25\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.5003 - accuracy: 0.7727 - val_loss: 0.5079 - val_accuracy: 0.7328\n",
      "Epoch 14/25\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.5035 - accuracy: 0.7355 - val_loss: 0.4960 - val_accuracy: 0.8244\n",
      "Epoch 15/25\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.4588 - accuracy: 0.7479 - val_loss: 0.4581 - val_accuracy: 0.7710\n",
      "Epoch 16/25\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.4943 - accuracy: 0.7603 - val_loss: 0.4425 - val_accuracy: 0.7939\n",
      "Epoch 17/25\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.4465 - accuracy: 0.7645 - val_loss: 0.4711 - val_accuracy: 0.7786\n",
      "Epoch 18/25\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.4189 - accuracy: 0.7893 - val_loss: 0.4390 - val_accuracy: 0.8092\n",
      "Epoch 19/25\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.4182 - accuracy: 0.8182 - val_loss: 0.4519 - val_accuracy: 0.8473\n",
      "Epoch 20/25\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.4299 - accuracy: 0.8099 - val_loss: 0.4229 - val_accuracy: 0.7939\n",
      "Epoch 21/25\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.4426 - accuracy: 0.7810 - val_loss: 0.6539 - val_accuracy: 0.7176\n",
      "Epoch 22/25\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.4921 - accuracy: 0.7810 - val_loss: 0.4487 - val_accuracy: 0.7786\n",
      "Epoch 23/25\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.4170 - accuracy: 0.8058 - val_loss: 0.4061 - val_accuracy: 0.8092\n",
      "Epoch 24/25\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.4141 - accuracy: 0.7934 - val_loss: 0.4727 - val_accuracy: 0.7710\n",
      "Epoch 25/25\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.3978 - accuracy: 0.8347 - val_loss: 0.4353 - val_accuracy: 0.7939\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "\n",
    "history = model.fit(X_train, y_train, \n",
    "                    validation_data=(X_test, y_test), \n",
    "                    epochs=25, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "b4b36ef9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.43525972962379456, 0.7938931584358215]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the model\n",
    "\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "scores\n",
    "\n",
    "# In results, first is loss, second is accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "dd667ef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.44\n",
      "accuracy: 79.39%\n"
     ]
    }
   ],
   "source": [
    "# extract the accuracy from model.evaluate\n",
    "\n",
    "print(\"%s: %.2f\" % (model.metrics_names[0], scores[0]))\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01936f84",
   "metadata": {},
   "source": [
    "## Wide and Deep network with RandomGridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "a0caba2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# If you don't have the following installed, from command line '!pip install scikeras'\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from keras.initializers import GlorotNormal\n",
    "\n",
    "score_measure = \"recall\"\n",
    "kfolds = 5\n",
    "\n",
    "def build_clf(hidden_layer_sizes, dropout):\n",
    "    ann = tf.keras.models.Sequential()\n",
    "    ann.add(keras.layers.Input(shape=5)),\n",
    "    for hidden_layer_size in hidden_layer_sizes:\n",
    "        model.add(keras.layers.Dense(hidden_layer_size, kernel_initializer= tf.keras.initializers.GlorotNormal(), \n",
    "                                     bias_initializer=keras.initializers.RandomNormal(mean=0.0, stddev=0.05, seed=None), activation=\"relu\"))\n",
    "        model.add(keras.layers.Dropout(dropout))\n",
    "    ann.add(tf.keras.layers.Dense(4, activation='softmax'))\n",
    "    ann.compile(loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
    "    return ann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "941f7ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scikeras.wrappers import KerasClassifier\n",
    "\n",
    "keras_clf = KerasClassifier(\n",
    "    model=build_clf,\n",
    "    hidden_layer_sizes=5,\n",
    "    dropout = 0.0\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "e9fdb134",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['model', 'build_fn', 'warm_start', 'random_state', 'optimizer', 'loss', 'metrics', 'batch_size', 'validation_batch_size', 'verbose', 'callbacks', 'validation_split', 'shuffle', 'run_eagerly', 'epochs', 'hidden_layer_sizes', 'dropout', 'class_weight'])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "params = {\n",
    "    'optimizer__learning_rate': [0.0005, 0.001, 0.005],\n",
    "    'model__hidden_layer_sizes': [(100,100,100),(100,150,100)],\n",
    "    'model__dropout': [0, 0.1],\n",
    "    'batch_size':[20, 60, 100],\n",
    "    'epochs':[10, 50, 100],\n",
    "    'optimizer':[\"adam\",'sgd']\n",
    "}\n",
    "keras_clf.get_params().keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "fdd0bc39",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_search_cv = RandomizedSearchCV(estimator=keras_clf, param_distributions=params, scoring='accuracy', n_iter=50, cv=5)\n",
    "\n",
    "import sys\n",
    "sys.setrecursionlimit(10000) # note: the default is 3000 (python 3.9)\n",
    "\n",
    "earlystop = EarlyStopping(monitor='val_loss', patience=5, verbose=0, mode='auto')\n",
    "callback = [earlystop]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "4863c893",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5,\n",
       "                   estimator=KerasClassifier(dropout=0.0, hidden_layer_sizes=5, model=&lt;function build_clf at 0x000002308E5F4700&gt;),\n",
       "                   n_iter=50,\n",
       "                   param_distributions={&#x27;batch_size&#x27;: [20, 60, 100],\n",
       "                                        &#x27;epochs&#x27;: [10, 50, 100],\n",
       "                                        &#x27;model__dropout&#x27;: [0, 0.1],\n",
       "                                        &#x27;model__hidden_layer_sizes&#x27;: [(100, 100,\n",
       "                                                                       100),\n",
       "                                                                      (100, 150,\n",
       "                                                                       100)],\n",
       "                                        &#x27;optimizer&#x27;: [&#x27;adam&#x27;, &#x27;sgd&#x27;],\n",
       "                                        &#x27;optimizer__learning_rate&#x27;: [0.0005,\n",
       "                                                                     0.001,\n",
       "                                                                     0.005]},\n",
       "                   scoring=&#x27;accuracy&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5,\n",
       "                   estimator=KerasClassifier(dropout=0.0, hidden_layer_sizes=5, model=&lt;function build_clf at 0x000002308E5F4700&gt;),\n",
       "                   n_iter=50,\n",
       "                   param_distributions={&#x27;batch_size&#x27;: [20, 60, 100],\n",
       "                                        &#x27;epochs&#x27;: [10, 50, 100],\n",
       "                                        &#x27;model__dropout&#x27;: [0, 0.1],\n",
       "                                        &#x27;model__hidden_layer_sizes&#x27;: [(100, 100,\n",
       "                                                                       100),\n",
       "                                                                      (100, 150,\n",
       "                                                                       100)],\n",
       "                                        &#x27;optimizer&#x27;: [&#x27;adam&#x27;, &#x27;sgd&#x27;],\n",
       "                                        &#x27;optimizer__learning_rate&#x27;: [0.0005,\n",
       "                                                                     0.001,\n",
       "                                                                     0.005]},\n",
       "                   scoring=&#x27;accuracy&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: KerasClassifier</label><div class=\"sk-toggleable__content\"><pre>KerasClassifier(\n",
       "\tmodel=&lt;function build_clf at 0x000002308E5F4700&gt;\n",
       "\tbuild_fn=None\n",
       "\twarm_start=False\n",
       "\trandom_state=None\n",
       "\toptimizer=rmsprop\n",
       "\tloss=None\n",
       "\tmetrics=None\n",
       "\tbatch_size=None\n",
       "\tvalidation_batch_size=None\n",
       "\tverbose=1\n",
       "\tcallbacks=None\n",
       "\tvalidation_split=0.0\n",
       "\tshuffle=True\n",
       "\trun_eagerly=False\n",
       "\tepochs=1\n",
       "\thidden_layer_sizes=5\n",
       "\tdropout=0.0\n",
       "\tclass_weight=None\n",
       ")</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KerasClassifier</label><div class=\"sk-toggleable__content\"><pre>KerasClassifier(\n",
       "\tmodel=&lt;function build_clf at 0x000002308E5F4700&gt;\n",
       "\tbuild_fn=None\n",
       "\twarm_start=False\n",
       "\trandom_state=None\n",
       "\toptimizer=rmsprop\n",
       "\tloss=None\n",
       "\tmetrics=None\n",
       "\tbatch_size=None\n",
       "\tvalidation_batch_size=None\n",
       "\tverbose=1\n",
       "\tcallbacks=None\n",
       "\tvalidation_split=0.0\n",
       "\tshuffle=True\n",
       "\trun_eagerly=False\n",
       "\tepochs=1\n",
       "\thidden_layer_sizes=5\n",
       "\tdropout=0.0\n",
       "\tclass_weight=None\n",
       ")</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=KerasClassifier(dropout=0.0, hidden_layer_sizes=5, model=<function build_clf at 0x000002308E5F4700>),\n",
       "                   n_iter=50,\n",
       "                   param_distributions={'batch_size': [20, 60, 100],\n",
       "                                        'epochs': [10, 50, 100],\n",
       "                                        'model__dropout': [0, 0.1],\n",
       "                                        'model__hidden_layer_sizes': [(100, 100,\n",
       "                                                                       100),\n",
       "                                                                      (100, 150,\n",
       "                                                                       100)],\n",
       "                                        'optimizer': ['adam', 'sgd'],\n",
       "                                        'optimizer__learning_rate': [0.0005,\n",
       "                                                                     0.001,\n",
       "                                                                     0.005]},\n",
       "                   scoring='accuracy')"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f0cd95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 0s/step\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 9ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "3/3 [==============================] - 0s 9ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 10ms/step\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 296ms/step\n",
      "1/1 [==============================] - 0s 87ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "3/3 [==============================] - 0s 609us/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n"
     ]
    }
   ],
   "source": [
    "_ = rnd_search_cv.fit(X_train, y_train, callbacks=callback, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb163e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_search_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3df2b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_net = rnd_search_cv.best_estimator_\n",
    "print(rnd_search_cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21aa377f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "y_pred = best_net.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc984717",
   "metadata": {},
   "source": [
    "Decision tree model using the randomsearch is considered to be the best fitting model with a accuracy value of 85.4%. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd05655",
   "metadata": {},
   "source": [
    "Accuracies for,\n",
    "\n",
    "Neural Network 77%\n",
    "\n",
    "NN with Randomsearch 66%\n",
    "\n",
    "NN with Gridsearch 75%\n",
    "\n",
    "Deep network 72.52%\n",
    "\n",
    "wide and deep network 71%\n",
    "\n",
    "wide and deep network using randomgridesearch 68%."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
