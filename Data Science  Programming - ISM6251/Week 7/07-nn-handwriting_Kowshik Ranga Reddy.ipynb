{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w0tyra0NWJvI"
   },
   "source": [
    "## MNIST machine learning exercise\n",
    "\n",
    "In this exercise we will compare the performance of three different modeling approaches at predicting handwritten numbers. \n",
    "\n",
    "We use the MNIST data set;\n",
    "\n",
    "![mnist data](https://upload.wikimedia.org/wikipedia/commons/2/27/MnistExamples.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pmAFVhDJXFBb"
   },
   "source": [
    "## Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "48VnFR9cXFP0"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import datasets\n",
    "\n",
    "import pandas as pd\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YI7yVb-VW2zi"
   },
   "source": [
    "## Load data and explore/get to know the data structure\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the MNIST digits dataset. It's originally from UCI machine learning library, but included in SKLearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "M8CjaVlYW2Jx",
    "outputId": "e90a4dd3-3781-477f-b02f-97ac3e75be91"
   },
   "outputs": [],
   "source": [
    "mnist = datasets.load_digits() # sklearn includes this data set .. https://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the dataset is stored in a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "5pPXrazAfUoL",
    "outputId": "593b0df0-7b98-4c9b-e01d-36930d653723"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'feature_names', 'target_names', 'images', 'DESCR'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note thjat there are 1797 images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "rTQ7qNp4ffaW",
    "outputId": "3d267533-ac01-4747-abee-369aae5d3d79"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1797\n"
     ]
    }
   ],
   "source": [
    "print(len(mnist.data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Images are 8x8 grid of values epresenting the gray level for each pixel (16 levels of grey -- from 0 (black) to 15 (white)). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "id": "B0ZaSvLlfva0",
    "outputId": "7735e16a-6f2e-41cd-e4e3-55c1dbd5a89d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  5., 13.,  9.,  1.,  0.,  0.],\n",
       "       [ 0.,  0., 13., 15., 10., 15.,  5.,  0.],\n",
       "       [ 0.,  3., 15.,  2.,  0., 11.,  8.,  0.],\n",
       "       [ 0.,  4., 12.,  0.,  0.,  8.,  8.,  0.],\n",
       "       [ 0.,  5.,  8.,  0.,  0.,  9.,  8.,  0.],\n",
       "       [ 0.,  4., 11.,  0.,  1., 12.,  7.,  0.],\n",
       "       [ 0.,  2., 14.,  5., 10., 12.,  0.,  0.],\n",
       "       [ 0.,  0.,  6., 13., 10.,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.images[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To analyze this, we simple turn this into a one dimensional array (so we will x1, x2, ... x63, x64). This has already been done for us, and is stored in the data key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "id": "sjDP19CWfT6S",
    "outputId": "f3643de4-6fc9-4810-d5d5-21fb633970fa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  5., 13.,  9.,  1.,  0.,  0.,  0.,  0., 13., 15., 10.,\n",
       "       15.,  5.,  0.,  0.,  3., 15.,  2.,  0., 11.,  8.,  0.,  0.,  4.,\n",
       "       12.,  0.,  0.,  8.,  8.,  0.,  0.,  5.,  8.,  0.,  0.,  9.,  8.,\n",
       "        0.,  0.,  4., 11.,  0.,  1., 12.,  7.,  0.,  0.,  2., 14.,  5.,\n",
       "       10., 12.,  0.,  0.,  0.,  0.,  6., 13., 10.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "id": "Pi5Fvsd_dry5",
    "outputId": "d61e56b6-99c4-486c-b4fa-523f3cb7f1d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "print(mnist.target[0])\n",
    "print(mnist.target[1])\n",
    "print(mnist.target[2])\n",
    "print(mnist.target[3])\n",
    "print(mnist.target[4])\n",
    "print(mnist.target[5])\n",
    "print(mnist.target[6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use matplotlib to display a sample of these images from the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "qW162_28WC60",
    "outputId": "c7bf771d-ebd1-4a42-e9e4-719d243b814a"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in np.random.choice(range(0,len(mnist.images)), 4): # choose 4 at random\n",
    "  plt.imshow(mnist.images[i], cmap='gray')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data into training and test sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(mnist.data, mnist.target, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "5WfGTWb3hYd-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 516 ms\n",
      "Wall time: 1.21 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "ann = MLPClassifier(hidden_layer_sizes=(60,50,40), solver='adam', max_iter=200)\n",
    "_ = ann.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = ann.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.98        43\n",
      "           1       1.00      1.00      1.00        35\n",
      "           2       0.97      1.00      0.99        36\n",
      "           3       0.95      0.98      0.96        41\n",
      "           4       0.95      0.97      0.96        38\n",
      "           5       0.97      0.97      0.97        30\n",
      "           6       1.00      1.00      1.00        37\n",
      "           7       0.97      0.95      0.96        37\n",
      "           8       0.96      0.93      0.95        29\n",
      "           9       0.94      0.97      0.96        34\n",
      "\n",
      "    accuracy                           0.97       360\n",
      "   macro avg       0.97      0.97      0.97       360\n",
      "weighted avg       0.97      0.97      0.97       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "{'solver': 'adam', 'max_iter': 5000, 'learning_rate_init': 0.001, 'learning_rate': 'constant', 'hidden_layer_sizes': (60, 40, 20), 'alpha': 0.2, 'activation': 'tanh'}\n",
      "CPU times: total: 6 s\n",
      "Wall time: 7min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "score_measure = \"accuracy\"\n",
    "kfolds = 5\n",
    "\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [ (50,), (70,),(50,30), (40,20), (60,40, 20), (70,50,40)],\n",
    "    'activation': ['logistic', 'tanh', 'relu'],\n",
    "    'solver': ['adam', 'sgd'],\n",
    "    'alpha': [0, .2, .5, .7, 1],\n",
    "    'learning_rate': ['constant', 'invscaling', 'adaptive'],\n",
    "    'learning_rate_init': [0.001, 0.01, 0.1, 0.2, 0.5],\n",
    "    'max_iter': [5000]\n",
    "}\n",
    "\n",
    "ann = MLPClassifier()\n",
    "grid_search = RandomizedSearchCV(estimator = ann, param_distributions=param_grid, cv=kfolds, n_iter=100,\n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = grid_search.fit(X_train, y_train)\n",
    "\n",
    "bestRecallTree = grid_search.best_estimator_\n",
    "\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99        43\n",
      "           1       1.00      1.00      1.00        35\n",
      "           2       1.00      1.00      1.00        36\n",
      "           3       0.98      1.00      0.99        41\n",
      "           4       1.00      1.00      1.00        38\n",
      "           5       0.94      1.00      0.97        30\n",
      "           6       1.00      1.00      1.00        37\n",
      "           7       1.00      0.95      0.97        37\n",
      "           8       0.96      0.93      0.95        29\n",
      "           9       0.97      0.94      0.96        34\n",
      "\n",
      "    accuracy                           0.98       360\n",
      "   macro avg       0.98      0.98      0.98       360\n",
      "weighted avg       0.98      0.98      0.98       360\n",
      "\n",
      "CPU times: total: 31.2 ms\n",
      "Wall time: 6.25 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = bestRecallTree.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      "{'activation': 'relu', 'alpha': 0.5, 'hidden_layer_sizes': (70,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.005, 'max_iter': 5000, 'solver': 'adam'}\n",
      "CPU times: total: 3.92 s\n",
      "Wall time: 3min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "score_measure = \"accuracy\"\n",
    "kfolds = 5\n",
    "\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [ (30,), (50,), (70,), (90,)],\n",
    "    'activation': ['tanh', 'relu'],\n",
    "    'solver': ['adam'],\n",
    "    'alpha': [.5, .7, 1],\n",
    "    'learning_rate': ['adaptive', 'invscaling'],\n",
    "    'learning_rate_init': [0.005, 0.01, 0.15],\n",
    "    'max_iter': [5000]\n",
    "}\n",
    "\n",
    "ann = MLPClassifier()\n",
    "grid_search = GridSearchCV(estimator = ann, param_grid=param_grid, cv=kfolds, \n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = grid_search.fit(X_train, y_train)\n",
    "\n",
    "bestRecallTree = grid_search.best_estimator_\n",
    "\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99        43\n",
      "           1       0.97      1.00      0.99        35\n",
      "           2       1.00      1.00      1.00        36\n",
      "           3       0.98      1.00      0.99        41\n",
      "           4       0.97      1.00      0.99        38\n",
      "           5       0.97      0.93      0.95        30\n",
      "           6       1.00      1.00      1.00        37\n",
      "           7       1.00      0.97      0.99        37\n",
      "           8       1.00      0.97      0.98        29\n",
      "           9       0.94      0.97      0.96        34\n",
      "\n",
      "    accuracy                           0.98       360\n",
      "   macro avg       0.98      0.98      0.98       360\n",
      "weighted avg       0.98      0.98      0.98       360\n",
      "\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 8.53 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = bestRecallTree.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision tree model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = DecisionTreeClassifier()\n",
    "classifier = classifier.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.96        43\n",
      "           1       0.94      0.83      0.88        35\n",
      "           2       0.89      0.86      0.87        36\n",
      "           3       0.81      0.71      0.75        41\n",
      "           4       0.87      0.89      0.88        38\n",
      "           5       0.78      0.97      0.87        30\n",
      "           6       0.95      1.00      0.97        37\n",
      "           7       0.86      0.86      0.86        37\n",
      "           8       0.81      0.90      0.85        29\n",
      "           9       0.74      0.74      0.74        34\n",
      "\n",
      "    accuracy                           0.87       360\n",
      "   macro avg       0.86      0.87      0.86       360\n",
      "weighted avg       0.87      0.87      0.87       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision tree model using the randomsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 500 candidates, totalling 2500 fits\n",
      "The best accuracy score is 0.8448219125048393\n",
      "... with parameters: {'min_samples_split': 13, 'min_samples_leaf': 1, 'min_impurity_decrease': 0.0031, 'max_leaf_nodes': 172, 'max_depth': 39, 'criterion': 'entropy'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dkrre\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "55 fits failed out of a total of 2500.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "55 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\dkrre\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\dkrre\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 937, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\dkrre\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 250, in fit\n",
      "    raise ValueError(\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\dkrre\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan 0.1892712  0.72860288 0.71815476 0.72793022 0.7835511\n",
      " 0.70218012 0.79610192 0.73902923 0.71399293 0.72790844 0.83439799\n",
      " 0.77801974 0.75367547 0.71676103 0.79820703 0.67295054 0.79750532\n",
      " 0.71745548 0.77662602 0.74041812 0.77033488 0.71814992 0.74041812\n",
      " 0.79054152 0.63118467 0.76477449 0.76480836        nan 0.78146777\n",
      " 0.75640002 0.78843157        nan 0.84482191 0.79680604 0.72023326\n",
      " 0.75432636 0.79818041 0.76615612 0.75715254 0.7703736  0.76547377\n",
      " 0.70774535 0.77869241 0.55324477 0.71468738 0.82602594 0.80026374\n",
      " 0.7648132  0.7153794  0.52750919 0.82048248 0.73624903 0.76758372\n",
      " 0.74321283 0.72373693 0.77938928 0.77384098 0.75083479 0.76828542\n",
      " 0.73347851 0.8197711  0.74876355 0.81419135 0.75710172 0.31384533\n",
      " 0.72860288 0.79400165 0.71468738 0.40155827 0.77938928 0.78636034\n",
      " 0.80376016 0.70356901 0.54349835 0.70843738 0.84136905 0.73902439\n",
      " 0.77033488 0.44886276 0.70356901 0.78289295 0.76755952 0.72442654\n",
      " 0.72931185 0.60753484 0.71399293 0.34239015 0.76615854 0.71676103\n",
      " 0.19485579 0.75993757 0.77662602 0.71610046 0.82254646 0.80236401\n",
      " 0.75432636 0.76965496 0.80446187        nan 0.69658585 0.34239015\n",
      " 0.75994483 0.70774535 0.71746032 0.75500629 0.78009824 0.72860288\n",
      "        nan 0.72794232 0.75083479 0.80307298 0.7251234  0.69314266\n",
      " 0.78565621 0.74737708 0.79400165 0.7251234  0.70566444        nan\n",
      " 0.83230739 0.72163424 0.72512098 0.74041812 0.75362466 0.79260792\n",
      " 0.76408004 0.79748839 0.7835753  0.72373693 0.72512098 0.73418264\n",
      " 0.75154133 0.79054152 0.72093738 0.82394744 0.78286876 0.71676103\n",
      " 0.7675571  0.76968157 0.65133566 0.72442654 0.7251234  0.73624661\n",
      " 0.70287698 0.65133566 0.72648326 0.70426345 0.71329849 0.74041812\n",
      " 0.70356901 0.70356901 0.75710172 0.82394986 0.74669715 0.70287698\n",
      " 0.78844367 0.75083479 0.75645083 0.71676103 0.71676103 0.8023616\n",
      " 0.76203542 0.72931185 0.75432636 0.77939412 0.83996322 0.76477449\n",
      " 0.53931959 0.72931185 0.77523955 0.76894599 0.78984466 0.82464431\n",
      " 0.75432636 0.79678668 0.76828542 0.72512098 0.71816202 0.52750919\n",
      " 0.75640002 0.81629404 0.71816202 0.31384533 0.73902923 0.79330478\n",
      " 0.41963318 0.61730062 0.56927023 0.76131678 0.75226965 0.75226965\n",
      " 0.72094948 0.72931185 0.75432636 0.75993757 0.75083479 0.71815476\n",
      " 0.70287698 0.8322953  0.74321283 0.81559717 0.69593254 0.78566105\n",
      " 0.78704994 0.71399293 0.72442654 0.75784456 0.77869483 0.79263211\n",
      " 0.74041812 0.75993757 0.75640002 0.77799313 0.75014034 0.787033\n",
      " 0.77869725 0.34239015 0.77176249 0.79190863        nan 0.76202091\n",
      " 0.70705575 0.79542199 0.75226965 0.80583624 0.71676103 0.78148471\n",
      " 0.76063686 0.71885405 0.75990128 0.72093738 0.34239015 0.73901713\n",
      " 0.7243975  0.75293264 0.7675934  0.40155827 0.81559717 0.78217431\n",
      " 0.7251234  0.7473916  0.72650987 0.7251234  0.54140534 0.77315379\n",
      " 0.19485579 0.71746032 0.78428184 0.70705575 0.71468738 0.75645083\n",
      " 0.73624903 0.76896535 0.70774535 0.75154133 0.71329849 0.76202091\n",
      " 0.75780343 0.31384533 0.75994483 0.19485579 0.76686024 0.81769503\n",
      " 0.34239015 0.79124081 0.78147745 0.71885405 0.75226965 0.81768777\n",
      "        nan 0.70218012 0.72163424        nan 0.75851723 0.72931185\n",
      " 0.79819251 0.71329849 0.76824913        nan 0.6138284  0.70218012\n",
      " 0.76341947 0.77037602 0.71816202 0.68201461 0.7154278  0.76968157\n",
      " 0.74041812 0.73624661 0.7153794  0.79681814 0.44886276 0.74876355\n",
      " 0.79472029 0.72928523 0.76201849 0.74667296 0.71885405 0.53029423\n",
      " 0.75226965 0.76338076 0.77798103 0.77872387 0.74041812 0.68963899\n",
      " 0.45860676 0.70287698 0.80584592 0.78218399 0.78146777 0.70218012\n",
      " 0.1892712  0.77314895 0.53029423 0.76894599 0.71676103 0.76828058\n",
      " 0.72442654 0.78147987 0.75083479 0.75223819 0.71258469 0.78983498\n",
      " 0.72581301 0.72931185 0.71885405 0.80306814 0.44886276 0.70705575\n",
      " 0.82396438 0.48990031 0.75154133 0.52751161 0.71468738 0.72093738\n",
      " 0.72650987 0.76758372 0.40155827 0.7153794  0.78706446 0.78984466\n",
      " 0.72789876 0.74041812 0.74667296 0.72373693 0.69593254 0.77106562\n",
      " 0.76058362 0.80514179 0.77732772 0.74739402 0.72442654 0.80237611\n",
      " 0.79122387 0.76478175 0.74669715 0.82117451 0.76825155 0.78564895\n",
      " 0.72648326 0.78287844 0.73624903 0.71816202 0.73485288 0.71814992\n",
      " 0.72930701 0.72860288 0.75154133 0.53305991 0.70705575 0.72442654\n",
      " 0.31384533 0.75500629 0.7494459  0.77454994 0.34239015 0.75919957\n",
      " 0.76756194 0.74667296 0.75226965 0.7933314  0.70705575 0.44886276\n",
      " 0.7543312  0.73485288 0.72442654 0.78147745 0.71816202 0.75990128\n",
      " 0.71468738 0.67088173 0.75015244 0.73485288 0.65973674 0.66392276\n",
      " 0.7251234  0.78147745 0.31384533 0.72581301 0.71815476        nan\n",
      " 0.69453397 0.76828542 0.79262485 0.1892712  0.75432636 0.53652729\n",
      " 0.70287698 0.52750919 0.77245451 0.83995112 0.74669715 0.77941105\n",
      " 0.71814992 0.72093738 0.70356901 0.75715496 0.7536658  0.78984466\n",
      " 0.7731296  0.71745548 0.71399293 0.70774535 0.70566444 0.76480836\n",
      " 0.76688928 0.71049894 0.79262727 0.78705478 0.76965012 0.79678426\n",
      " 0.77313444 0.64721254 0.71329849 0.72512098 0.34239015 0.7376355\n",
      " 0.71468738 0.70705575 0.76968157 0.70774535 0.76203058 0.68754113\n",
      " 0.70355449 0.79333382 0.72789876 0.66391067 0.7905512  0.81838463\n",
      " 0.79609224 0.51285811 0.77523471 0.74667296 0.54141018 0.72442654\n",
      " 0.69035521 0.70774535 0.1892712  0.82046312 0.768283   0.74669715\n",
      " 0.74321283 0.73902923 0.70426345 0.78845093 0.1892712  0.78565621\n",
      " 0.78843883 0.19485579 0.72373693 0.77939412 0.75501113 0.72442654\n",
      " 0.76690621 0.7703494  0.76825155 0.73413908 0.69658585 0.81350416\n",
      " 0.81142083 0.75576123 0.76825155 0.76688928 0.53238482 0.74669715\n",
      " 0.73624661 0.75855594 0.34239015 0.70566444 0.76757404 0.74736982\n",
      " 0.77103901 0.1892712  0.72233353 0.72373693 0.79052942 0.54141018\n",
      " 0.7251234  0.70426345]\n",
      "  warnings.warn(\n",
      "C:\\Users\\dkrre\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the train scores are non-finite: [       nan 0.19728702 0.78949665 0.77679797 0.78375041 0.83855254\n",
      " 0.76426957 0.84846755 0.77244455 0.7722726  0.76460968 0.92936784\n",
      " 0.84447013 0.81854906 0.7546983  0.86151845 0.70494131 0.86360631\n",
      " 0.75522049 0.83681568 0.80184917 0.81628425 0.75556862 0.80184917\n",
      " 0.85212533 0.64943868 0.81663269 0.82202793        nan 0.83907383\n",
      " 0.80167072 0.84707822        nan 0.93893518 0.85351254 0.7546983\n",
      " 0.78897007 0.86082204 0.81367495 0.81959284 0.83542332 0.8150658\n",
      " 0.7595715  0.82741938 0.58333053 0.77401294 0.91249056 0.86273569\n",
      " 0.83872888 0.77140258 0.54679653 0.8891791  0.76792144 0.82881235\n",
      " 0.80376252 0.78793022 0.82637545 0.83785916 0.79436213 0.81733061\n",
      " 0.79384629 0.90361933 0.78375237 0.89109275 0.80027896 0.31524002\n",
      " 0.78949665 0.85873493 0.77401294 0.41857857 0.82637545 0.84498853\n",
      " 0.87839361 0.76357332 0.57237098 0.76617944 0.93997957 0.7667033\n",
      " 0.81628425 0.46572748 0.76357332 0.84847103 0.81089023 0.7585259\n",
      " 0.79123487 0.63117145 0.7722726  0.35716563 0.81176115 0.7546983\n",
      " 0.19485072 0.8133291  0.83681568 0.7734856  0.90065948 0.87004412\n",
      " 0.78897007 0.82376221 0.87282688        nan 0.72546865 0.35716563\n",
      " 0.82707201 0.7595715  0.77801582 0.80167072 0.84046589 0.78949665\n",
      "        nan 0.78479631 0.79436213 0.86865161 0.75904764 0.74390949\n",
      " 0.83890022 0.79471117 0.85734332 0.75904764 0.76131154        nan\n",
      " 0.93215136 0.75643819 0.764267   0.80184917 0.79279631 0.85334105\n",
      " 0.81489265 0.85246831 0.85072903 0.78793022 0.764267   0.78235547\n",
      " 0.78427426 0.85142907 0.75609036 0.90640194 0.838553   0.7546983\n",
      " 0.81819881 0.82550664 0.66927461 0.76235229 0.75904764 0.76983479\n",
      " 0.75870163 0.66927461 0.75400235 0.76548802 0.77279479 0.80184917\n",
      " 0.76357332 0.76357332 0.80027896 0.89839921 0.80532804 0.75870163\n",
      " 0.84255315 0.79436213 0.81245998 0.7546983  0.7546983  0.87230545\n",
      " 0.81941847 0.77452651 0.80428108 0.84168252 0.93928422 0.81576297\n",
      " 0.56593454 0.79123487 0.83716396 0.81785083 0.85212533 0.91562266\n",
      " 0.78897007 0.86430106 0.81733061 0.764267   0.78253831 0.54679653\n",
      " 0.80167072 0.89596458 0.78253831 0.31524002 0.77244455 0.85838695\n",
      " 0.43510788 0.64456624 0.59307451 0.81663465 0.80915458 0.80915458\n",
      " 0.78601673 0.79123487 0.78897007 0.8133291  0.79436213 0.77679797\n",
      " 0.75870163 0.92014621 0.80376252 0.89961766 0.72911825 0.83594309\n",
      " 0.84237893 0.7722726  0.7585259  0.81437303 0.82567919 0.8606454\n",
      " 0.80184917 0.8133291  0.80167072 0.83315957 0.79279631 0.84255496\n",
      " 0.83855148 0.35716563 0.84516775 0.85421213        nan 0.8209843\n",
      " 0.76235547 0.86690854 0.80915458 0.87317319 0.7546983  0.83698672\n",
      " 0.81785326 0.77627578 0.80340909 0.77940788 0.35716563 0.77348757\n",
      " 0.75104386 0.80393325 0.82863798 0.41857857 0.88952798 0.83211564\n",
      " 0.75904764 0.80706762 0.75835184 0.75904764 0.5674996  0.83994596\n",
      " 0.19485072 0.77801582 0.86273765 0.76235547 0.77401294 0.81245998\n",
      " 0.76792144 0.82828637 0.7595715  0.78427426 0.77279479 0.8209843\n",
      " 0.792623   0.31524002 0.82707201 0.19485072 0.8124562  0.88813562\n",
      " 0.35716563 0.85577871 0.82602687 0.77627578 0.80915458 0.8975304\n",
      "        nan 0.76426957 0.75643819        nan 0.80706308 0.79123487\n",
      " 0.87509063 0.77279479 0.81176115        nan 0.63934431 0.76426957\n",
      " 0.81298187 0.82550664 0.78253831 0.71729292 0.7578245  0.82550664\n",
      " 0.80184917 0.76983479 0.77140258 0.86151845 0.46572748 0.78375237\n",
      " 0.86499746 0.76357104 0.82376751 0.77975192 0.77627578 0.54314451\n",
      " 0.80915458 0.81141333 0.83263753 0.85560434 0.80184917 0.71694373\n",
      " 0.47999319 0.75870163 0.87387157 0.84168419 0.83907383 0.76426957\n",
      " 0.19728702 0.83733712 0.54314451 0.8173291  0.7546983  0.83594536\n",
      " 0.7585259  0.8406395  0.79436213 0.80114822 0.75017202 0.84690218\n",
      " 0.75800401 0.79123487 0.77627578 0.88117365 0.46572748 0.76235547\n",
      " 0.91840693 0.50399909 0.78427426 0.5410568  0.77401294 0.77940788\n",
      " 0.75835184 0.82881235 0.41857857 0.77140258 0.85108094 0.85142907\n",
      " 0.76444106 0.80184917 0.77975192 0.78793022 0.72911825 0.83437984\n",
      " 0.81106596 0.86760646 0.839077   0.80741605 0.76235229 0.86865161\n",
      " 0.85716669 0.81036425 0.80532804 0.9022256  0.81889507 0.84499035\n",
      " 0.75400235 0.84168419 0.76792144 0.78253831 0.76983479 0.75556862\n",
      " 0.79488902 0.78949665 0.78427426 0.55845355 0.76235547 0.76235229\n",
      " 0.31524002 0.80167072 0.79645015 0.84307746 0.35716563 0.80880372\n",
      " 0.81106429 0.77975192 0.80915458 0.86029667 0.76235547 0.46572748\n",
      " 0.81071768 0.76983479 0.7585259  0.83142029 0.78253831 0.80340909\n",
      " 0.77401294 0.69936989 0.78322988 0.76983479 0.70076361 0.70111235\n",
      " 0.75904764 0.82602687 0.31524002 0.75800401 0.77679797        nan\n",
      " 0.74495342 0.81733061 0.85472933 0.19728702 0.78897007 0.56349945\n",
      " 0.75870163 0.54679653 0.83194521 0.93615045 0.80532804 0.84794884\n",
      " 0.75556862 0.77940788 0.76357332 0.8190711  0.8093291  0.85142907\n",
      " 0.82463556 0.75522049 0.7722726  0.7595715  0.76131154 0.82202793\n",
      " 0.82881235 0.73921111 0.85960601 0.8451626  0.82880872 0.86064797\n",
      " 0.83837772 0.674665   0.77279479 0.764267   0.35716563 0.76705142\n",
      " 0.77401294 0.76235547 0.82550664 0.7595715  0.81298187 0.71485602\n",
      " 0.75835153 0.8672606  0.76444106 0.70198191 0.85786188 0.90274886\n",
      " 0.85734272 0.53287956 0.83368404 0.77975192 0.55688637 0.7585259\n",
      " 0.74129958 0.7595715  0.19728702 0.90396791 0.82950921 0.80532804\n",
      " 0.80376252 0.77244455 0.76548802 0.85369054 0.19728702 0.84533757\n",
      " 0.85194808 0.19485072 0.78793022 0.83855118 0.80114852 0.7585259\n",
      " 0.82498505 0.83350619 0.81698097 0.76339698 0.72546865 0.88239634\n",
      " 0.89196322 0.81507065 0.81698097 0.82881235 0.54401408 0.80532804\n",
      " 0.76983479 0.82602808 0.35716563 0.76131154 0.8293294  0.78218716\n",
      " 0.8291567  0.19728702 0.75817338 0.78793022 0.85594929 0.55688637\n",
      " 0.75904764 0.76548802]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"accuracy\"\n",
    "kfolds = 5\n",
    "\n",
    "param_grid = {\n",
    "    'min_samples_split': np.arange(1,60),  \n",
    "    'min_samples_leaf': np.arange(1,50),\n",
    "    'min_impurity_decrease': np.arange(0.0001, 0.01, 0.0005),\n",
    "    'max_leaf_nodes': np.arange(5, 200), \n",
    "    'max_depth': np.arange(1,50), \n",
    "    'criterion': ['entropy', 'gini'],\n",
    "}\n",
    "\n",
    "dtree = DecisionTreeClassifier()\n",
    "rand_search = RandomizedSearchCV(estimator = dtree, param_distributions=param_grid, cv=kfolds, n_iter=500,\n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1, return_train_score=True)\n",
    "\n",
    "_ = rand_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"The best {score_measure} score is {rand_search.best_score_}\")\n",
    "print(f\"... with parameters: {rand_search.best_params_}\")\n",
    "\n",
    "bestRecallTree = rand_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.98      0.94        43\n",
      "           1       0.91      0.91      0.91        35\n",
      "           2       0.84      0.89      0.86        36\n",
      "           3       0.92      0.83      0.87        41\n",
      "           4       0.80      0.92      0.85        38\n",
      "           5       0.88      0.97      0.92        30\n",
      "           6       0.97      0.97      0.97        37\n",
      "           7       1.00      0.81      0.90        37\n",
      "           8       1.00      0.76      0.86        29\n",
      "           9       0.79      0.88      0.83        34\n",
      "\n",
      "    accuracy                           0.89       360\n",
      "   macro avg       0.90      0.89      0.89       360\n",
      "weighted avg       0.90      0.89      0.89       360\n",
      "\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = bestRecallTree.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, bestRecallTree.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision tree model using the Gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3200 candidates, totalling 16000 fits\n",
      "The best accuracy score is 0.8511057878435928\n",
      "... with parameters: {'criterion': 'entropy', 'max_depth': 40, 'max_leaf_nodes': 173, 'min_impurity_decrease': 0.004499999999999997, 'min_samples_leaf': 1, 'min_samples_split': 11}\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"accuracy\"\n",
    "kfolds = 5\n",
    "\n",
    "param_grid = {\n",
    "    'min_samples_split': np.arange(11,15),  \n",
    "    'min_samples_leaf': np.arange(1,3),\n",
    "    'min_impurity_decrease': np.arange(0.003, 0.005, 0.0001),\n",
    "    'max_leaf_nodes': np.arange(170,175), \n",
    "    'max_depth': np.arange(37,41), \n",
    "    'criterion': ['entropy'],\n",
    "}\n",
    "\n",
    "dtree = DecisionTreeClassifier()\n",
    "grid_search = GridSearchCV(estimator = dtree, param_grid=param_grid, cv=kfolds, \n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"The best {score_measure} score is {grid_search.best_score_}\")\n",
    "print(f\"... with parameters: {grid_search.best_params_}\")\n",
    "\n",
    "bestRecallTree = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94        43\n",
      "           1       0.94      0.89      0.91        35\n",
      "           2       0.87      0.92      0.89        36\n",
      "           3       0.87      0.80      0.84        41\n",
      "           4       0.80      0.92      0.85        38\n",
      "           5       0.88      0.97      0.92        30\n",
      "           6       0.97      0.97      0.97        37\n",
      "           7       0.97      0.81      0.88        37\n",
      "           8       0.96      0.79      0.87        29\n",
      "           9       0.79      0.88      0.83        34\n",
      "\n",
      "    accuracy                           0.89       360\n",
      "   macro avg       0.90      0.89      0.89       360\n",
      "weighted avg       0.90      0.89      0.89       360\n",
      "\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 15.7 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = bestRecallTree.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, bestRecallTree.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upon looking at the accuracy for Neural Net with GridsearchCV(98%) and Decision tree with GridsearchCV(89%), we can say that Neural net with GridsearchCV performs better than Decision tree with GridsearchCV with higher accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOig4eSm144+FaPk1GKk187",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "mnist_compete_3_models.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "b056086e24cb5602cbcb82122035cd3d6ee2ccbf5df29c16e348c108b0f83be3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
